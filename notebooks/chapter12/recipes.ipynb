{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\n",
    "    \"Ch12 - recipes ML model - are you a dessert?\"\n",
    ").config(\"spark.driver.memory\", \"8g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "food = spark.read.csv(\"/opt/spark/data/recipes/epi_r.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(food.count(), len(food.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "food.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def sanitize_column_name(name):\n",
    "    answer = name\n",
    "\n",
    "    for i, j in ((\" \", \"_\"), (\"-\", \"_\"), (\"/\", \"_\"), (\"&\", \"and\")):\n",
    "        answer = answer.replace(i, j)\n",
    "\n",
    "    return \"\".join([char for char in answer if char.isalpha() or char.isdigit() or char == \"_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "food = food.toDF(*[sanitize_column_name(name) for name in food.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_columns = [\"clove\"]\n",
    "\n",
    "for x in food.columns:\n",
    "    if x in interesting_columns:\n",
    "        food.select(x).summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max.rows\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_binary = food.agg(\n",
    "    *[(F.size(F.collect_set(x)) == 2).alias(x) for x in food.columns]\n",
    ").toPandas()\n",
    "\n",
    "is_binary.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food.agg(*[F.collect_set(x) for x in (\"cakeweek\", \"wasteless\")]).show(\n",
    "    1, False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food.where(\"cakeweek > 1.0 or wasteless > 1.0\").select(\n",
    "    \"title\", \"rating\", \"wasteless\", \"cakeweek\", food.columns[-1]\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = food.where(\n",
    "    (\n",
    "        F.col(\"cakeweek\").isin([0.0, 1.0]) | F.col(\"cakeweek\").isNull()\n",
    "    ) &\n",
    "    (\n",
    "        F.col(\"wasteless\").isin([0.0, 1.0]) | F.col(\"wasteless\").isNull()\n",
    "    )\n",
    ")\n",
    "\n",
    "print(food.count(), len(food.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDENTIFIERS = [\"title\"]\n",
    "CONTINUOUS_COLUMNS = [\n",
    "    \"rating\",\n",
    "    \"calories\",\n",
    "    \"protein\",\n",
    "    \"fat\",\n",
    "    \"sodium\",\n",
    "]\n",
    "\n",
    "TARGET_COLUMN = [\"dessert\"]\n",
    "\n",
    "BINARY_COLUMNS = [x for x in food.columns if x not in [*IDENTIFIERS, *CONTINUOUS_COLUMNS, *TARGET_COLUMN]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "food = food.dropna(how=\"all\", subset=[x for x in food.columns if x not in IDENTIFIERS])\n",
    "\n",
    "food = food.dropna(subset=TARGET_COLUMN)\n",
    "\n",
    "print(food.count(), len(food.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "food = food.fillna(0.0, subset=BINARY_COLUMNS)\n",
    "\n",
    "food.where(F.col(BINARY_COLUMNS[0]).isNull()).count() # => 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "@F.udf(T.BooleanType())\n",
    "def is_a_number(value: Optional[str]) -> bool:\n",
    "    if not value:\n",
    "        return True\n",
    "\n",
    "    try:\n",
    "        _ = float(value)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "food.where(~is_a_number(F.col(\"rating\"))).select(\n",
    "    *CONTINUOUS_COLUMNS\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for column in [\"rating\", \"calories\"]:\n",
    "    food = food.where(is_a_number(F.col(column)))\n",
    "    food = food.withColumn(column, F.col(column).cast(T.DoubleType()))\n",
    "\n",
    "print(food.count(), len(food.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "food.select(*CONTINUOUS_COLUMNS).summary(\n",
    "    \"mean\",\n",
    "    \"stddev\",\n",
    "    \"min\",\n",
    "    \"1%\",\n",
    "    \"5%\",\n",
    "    \"50%\",\n",
    "    \"95%\",\n",
    "    \"99%\",\n",
    "    \"max\",\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "inst_sum_of_binary_columns = [\n",
    "    F.sum(F.col(x)).alias(x) for x in BINARY_COLUMNS\n",
    "]\n",
    "\n",
    "sum_of_binary_columns = food.select(*inst_sum_of_binary_columns).head().asDict()\n",
    "\n",
    "num_rows = food.count()\n",
    "\n",
    "too_rare_features = [\n",
    "    k for k, v in sum_of_binary_columns.items() if v < 10 or v > (num_rows - 10)\n",
    "]\n",
    "\n",
    "print(len(too_rare_features))\n",
    "\n",
    "print(too_rare_features)\n",
    "\n",
    "BINARY_COLUMNS = list(set(BINARY_COLUMNS) - set(too_rare_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = food.withColumn(\"protein_ratio\", F.col(\"protein\") * 4 / F.col(\"calories\")).withColumn(\n",
    "    \"fat_ratio\", F.col(\"fat\") * 9 / F.col(\"calories\")\n",
    ")\n",
    "\n",
    "food = food.fillna(0.0, subset=[\"protein_ratio\", \"fat_ratio\"])\n",
    "\n",
    "CONTINUOUS_COLUMNS += [\"protein_ratio\", \"fat_ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the VectorAssembler transformer on the food data frame to create a new column,\n",
    "# continuous_features, that contains a Vector of all our continuous features.\n",
    "# A transformer is a preconfigured object that, as its name indicates, transforms a data frame.\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "continuous_features = VectorAssembler(\n",
    "    inputCols=CONTINUOUS_COLUMNS, outputCol=\"continuous_features\"\n",
    ")\n",
    "\n",
    "vector_food = food.select(CONTINUOUS_COLUMNS)\n",
    "\n",
    "for x in CONTINUOUS_COLUMNS:\n",
    "    vector_food = vector_food.where(~F.isnull(F.col(x)))\n",
    "\n",
    "print(\"Food count:\")\n",
    "print(food.count(), len(food.columns))\n",
    "print(\"Vector food count:\")\n",
    "print(vector_food.count(), len(vector_food.columns))\n",
    "\n",
    "vector_variable = continuous_features.transform(vector_food)\n",
    "\n",
    "vector_variable.select(\"continuous_features\").show(3, False)\n",
    "\n",
    "vector_variable.select(\"continuous_features\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "correlation = Correlation.corr(vector_variable, \"continuous_features\")\n",
    "\n",
    "correlation.printSchema()\n",
    "\n",
    "correlation_array = correlation.head()[0].toArray()\n",
    "\n",
    "correlation_pd = pd.DataFrame(\n",
    "    correlation_array,\n",
    "    index=CONTINUOUS_COLUMNS,\n",
    "    columns=CONTINUOUS_COLUMNS\n",
    ")\n",
    "\n",
    "print(correlation_pd.iloc[:, :4])\n",
    "\n",
    "print(correlation_pd.iloc[:, 4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "OLD_COLS = [\"calories\", \"protein\", \"fat\", \"sodium\"]\n",
    "NEW_COLS = [\"calories_i\", \"protein_i\", \"fat_i\", \"sodium_i\"]\n",
    "\n",
    "imputer = Imputer(strategy=\"mean\", inputCols=OLD_COLS, outputCols=NEW_COLS)\n",
    "\n",
    "imputer_model = imputer.fit(food)\n",
    "\n",
    "CONTINUOUS_COLUMNS = list(set(CONTINUOUS_COLUMNS) - set(OLD_COLS)) + NEW_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_imputed = imputer_model.transform(food)\n",
    "\n",
    "food_imputed.where(\"calories is null\").select(\"calories\", \"calories_i\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "CONTINUOUS_NB = [x for x in CONTINUOUS_COLUMNS if \"ratio\" not in x]\n",
    "\n",
    "continuous_assembler = VectorAssembler(\n",
    "    inputCols=CONTINUOUS_NB, outputCol=\"continuous\"\n",
    ")\n",
    "\n",
    "food_features = continuous_assembler.transform(food_imputed)\n",
    "\n",
    "continuous_scaler = MinMaxScaler(\n",
    "    inputCol=\"continuous\",\n",
    "    outputCol=\"continuous_scaled\"\n",
    ")\n",
    "\n",
    "food_features = continuous_scaler.fit(food_features).transform(food_features)\n",
    "\n",
    "food_features.select(\"continuous_scaled\").show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
